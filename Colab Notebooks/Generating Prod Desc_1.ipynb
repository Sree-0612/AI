{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHdeHikzEPmLr3MbXv/S1D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Hugging Face's Transformers library and GPT-2 model - No accurate results"],"metadata":{"id":"TNUBpuGpt-Zx"}},{"cell_type":"code","source":["!pip install transformers\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer"],"metadata":{"id":"BWzmkfgktwN3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3QRper6wRmg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163195595,"user_tz":-330,"elapsed":6157,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"26a2b03d-7d17-43e3-ef3a-3196aa2cd862"},"outputs":[{"output_type":"stream","name":"stdout","text":["Product Name: Zoho CRM\n","Description:\n","\n","Zoho is a brand of Japanese food and beverage company. ZOHO is the name of the company's flagship brand, ZHO. The company is based in Tokyo, Japan.\n",".\n"]}],"source":["# Load pre-trained GPT-2 model and tokenizer\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","# Function to generate product description\n","def generate_product_description(product_name):\n","\n","    input_text = \"Product Name: \" + product_name + \"\\nDescription:\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","    # Generate text based on input\n","    output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n","\n","    # Decode and return generated product description\n","    return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","# Input product name\n","product_name = \"Zoho CRM\"\n","\n","# Generate product description\n","description = generate_product_description(product_name)\n","print(description)"]},{"cell_type":"markdown","source":["Named Entity Recognition (NER)"],"metadata":{"id":"8jGn_sfEuVFe"}},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download en_core_web_sm"],"metadata":{"id":"FX7kBz2EuT01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pseudo code for integrating NER with GPT-2\n","\n","import spacy\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Load pre-trained GPT-2 model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# Load pre-trained spaCy NER model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Function to preprocess text and annotate product entities\n","def preprocess_with_ner(input_text):\n","    doc = nlp(input_text)\n","    annotated_text = input_text\n","    for ent in doc.ents:\n","        if ent.label_ == 'PRODUCT':\n","            annotated_text = annotated_text.replace(ent.text, f\"<PRODUCT>{ent.text}<PRODUCT>\")\n","    return annotated_text\n","\n","# Example input text with product names\n","input_text = \"Zoho CRM is a customer relationship management software.\"\n","\n","# Preprocess input text with NER annotations\n","annotated_text = preprocess_with_ner(input_text)\n","\n","# Tokenize the annotated text\n","input_ids = tokenizer.encode(annotated_text, return_tensors='pt')\n","\n","# Generate product description using fine-tuned GPT-2 model\n","output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n","generated_description = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsNzjFMIj4yW","executionInfo":{"status":"ok","timestamp":1720363923176,"user_tz":-330,"elapsed":8202,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"21c61170-26c8-465d-911f-111abb9f508c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Zoho CRM is a customer relationship management software. It is designed to help you manage your business and manage the relationships between your customers and your partners.\n","\n","The CRMs are designed for business, not for the customer. They are not designed as a replacement for a traditional CRMS. Instead, they are a way to manage relationships and to make sure that your relationships are as effective as possible. CRms are used to:\n","...\n",",. to ensure that you are able\n"]}]},{"cell_type":"markdown","source":["Sample dataset\n","\n"],"metadata":{"id":"lOq1rK9x28c4"}},{"cell_type":"code","source":["!pip install langchain-community\n","from langchain_community.llms import Ollama\n","\n","llm = Ollama(model=\"llama3\") # assuming you have Ollama installed and have llama3 model pulled with `ollama pull llama3`\n"],"metadata":{"id":"2oII0SpdkUvR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain-community\n","from langchain_community.llms import Ollama\n","\n","# Initialize the Ollama model\n","try:\n","    llm = Ollama(model=\"llama3\") # replace \"llama3\" with the name of the model you've pulled\n","except Exception as e:\n","    print(f\"Error initializing model: {e}\")\n","    llm = None\n","\n","# Function to generate product description\n","def generate_product_description(product_name):\n","    if llm is None:\n","        return \"Model not initialized.\"\n","    try:\n","        prompt = f\"Write a detailed product description for {product_name}.\"\n","        description = llm.invoke(prompt)\n","        return description\n","    except Exception as e:\n","        return f\"An error occurred while generating description: {e}\"\n","\n","# Get product name from user\n","product_name = input(\"Enter the product name: \")\n","\n","# Generate and print product description\n","description = generate_product_description(product_name)\n","print(f\"Product Description:\\n{description}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0OM5FvjnRqS","executionInfo":{"status":"ok","timestamp":1720179245819,"user_tz":-330,"elapsed":159646,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"3d870a49-4ffa-40ba-f54a-fa78f748976f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.6)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.83)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.8.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.20.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mEnter the product name: smart phone\n","Product Description:\n","An error occurred while generating description: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/generate (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb55546cac0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"]}]},{"cell_type":"code","source":["!pip install transformers torch\n","\n","from transformers import BertForQuestionAnswering, BertTokenizer\n","import torch\n","\n","# Load pre-trained BERT model and tokenizer\n","model_name = 'bert-base-uncased'\n","model = BertForQuestionAnswering.from_pretrained(model_name)\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","# Function to ask a question and get the answer using BERT\n","def ask_question(question, text):\n","    encoding = tokenizer(question, text, return_tensors='pt')\n","    input_ids = encoding['input_ids']\n","    token_type_ids = encoding['token_type_ids']\n","\n","    # Extract the start and end logits from the model output\n","    outputs = model(input_ids, token_type_ids=token_type_ids)\n","    start_logits = outputs.start_logits\n","    end_logits = outputs.end_logits\n","\n","    start_index = torch.argmax(start_logits)\n","    end_index = torch.argmax(end_logits)\n","\n","    answer_tokens = input_ids[0][start_index:end_index+1]\n","    answer = tokenizer.decode(answer_tokens)\n","\n","    return answer\n","\n","# Provide a context (text) and ask a question\n","context = \"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained transformer model.\"\n","question = \"What is BERT?\"\n","answer = ask_question(question, context)\n","\n","print(f\"Question: {question}\")\n","print(f\"Answer: {answer}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKhXJIKjxHI7","executionInfo":{"status":"ok","timestamp":1720181002299,"user_tz":-330,"elapsed":7814,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"ea48386c-1f57-4614-8c9c-a8c5fecaa8b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Question: What is BERT?\n","Answer: \n"]}]},{"cell_type":"code","source":["# Pseudo code for integrating NER with GPT-2\n","\n","import spacy\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Load pre-trained GPT-2 model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# Load pre-trained spaCy NER model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Function to preprocess text and annotate product entities\n","def preprocess_with_ner(input_text):\n","    doc = nlp(input_text)\n","    annotated_text = input_text\n","    for ent in doc.ents:\n","        if ent.label_ == 'PRODUCT':\n","            annotated_text = annotated_text.replace(ent.text, f\"<PRODUCT>{ent.text}<PRODUCT>\")\n","    return annotated_text\n","\n","# Get product name and description from user\n","product_name = input(\"Enter the product name: \")\n","product_description = input(\"Enter the product description: \")\n","\n","# Merge product name and description\n","input_text = f\"{product_name} {product_description}\"\n","\n","# Preprocess input text with NER annotations\n","annotated_text = preprocess_with_ner(input_text)\n","\n","# Tokenize the annotated text\n","input_ids = tokenizer.encode(annotated_text, return_tensors='pt')\n","\n","# Generate product description using fine-tuned GPT-2 model\n","output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n","generated_description = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyqQFYRKqlVC","executionInfo":{"status":"ok","timestamp":1720363889899,"user_tz":-330,"elapsed":55499,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"d7f52f3d-b621-41b0-a93a-ec89fc280cd8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the product name: clothes\n","Enter the product description: Fashion\n","clothes Fashion, and the \"I'm a Woman\" campaign.\n","\n","\"I think it's a very important issue for women to be able to say, 'I am a woman, I'm not a man,'\" she said. \"And I think that's what we need to do.\"\n",".@realDonaldTrump: \"Women are not the only ones who are being discriminated against. We need a strong, strong and inclusive government that will protect women and their rights.\" pic.twitter.com\n"]}]},{"cell_type":"code","source":["# Pseudo code for integrating NER with GPT-2\n","\n","import spacy\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# Load pre-trained GPT-2 model\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# Load pre-trained spaCy NER model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Function to preprocess text and annotate product entities\n","def preprocess_with_ner(input_text):\n","    doc = nlp(input_text)\n","    annotated_text = input_text\n","    for ent in doc.ents:\n","        if ent.label_ == 'PRODUCT':\n","            annotated_text = annotated_text.replace(ent.text, f\"<PRODUCT>{ent.text}<PRODUCT>\")\n","    return annotated_text\n","\n","# Example input text with product names\n","input_text = \"Discover the cutting-edge technology of the latest iPhone in the world of electronics.\"\n","\n","# Preprocess input text with NER annotations\n","annotated_text = preprocess_with_ner(input_text)\n","\n","# Tokenize the annotated text\n","input_ids = tokenizer.encode(annotated_text, return_tensors='pt')\n","\n","# Generate product description using fine-tuned GPT-2 model\n","output = model.generate(input_ids, max_length=100, num_return_sequences=1, no_repeat_ngram_size=2, pad_token_id=tokenizer.eos_token_id)\n","generated_description = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_n0zICp4rlY_","executionInfo":{"status":"ok","timestamp":1720364013965,"user_tz":-330,"elapsed":6902,"user":{"displayName":"Sreenidhi Ramprasath","userId":"16637636708478609967"}},"outputId":"228c16ec-d244-4127-b34b-db667c5bd00d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Discover the cutting-edge technology of the latest iPhone in the world of electronics.\n","\n","The iPhone 6 Plus is the first iPhone to feature a 5.5-inch display, and it's the only one to have a fingerprint sensor. The iPhone 5s is also the last iPhone that has a built-in camera. It's also one of only two phones to be available in a single color.\n"]}]}]}